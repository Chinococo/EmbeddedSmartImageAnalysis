{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.cuda().eval().half()\n",
    "model.load_state_dict(torch.load('resnet18_finetuned_fp16_pruned.pth'))\n",
    "device = torch.device('cuda')\n",
    "print(\"模型成功加载\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch2trt import torch2trt\n",
    "\n",
    "data = torch.zeros((1, 3, 134, 224)).cuda().half()\n",
    "\n",
    "model_trt = torch2trt(model, [data], fp16_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trt.state_dict(), 'best_steering_model_xy_trt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-scheduling",
   "metadata": {},
   "source": [
    "# 預測\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-frontier",
   "metadata": {},
   "source": [
    "## 載入TRT 循線resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-connection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_steering_model_xy_trt.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-people",
   "metadata": {},
   "source": [
    "### 設定欲處理圖片方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "computational-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "device = torch.device('cuda')\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-chair",
   "metadata": {},
   "source": [
    "#### 開啟相機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "french-principle",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not initialize camera.  Please see error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.3-py3.6.egg/jetbot/camera/opencv_gst_camera.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not read image from camera.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not read image from camera.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-08a4e9d3bcfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjetbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCamera\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgr8_to_jpeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.3-py3.6.egg/jetbot/camera/opencv_gst_camera.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             raise RuntimeError(\n\u001b[0;32m---> 37\u001b[0;31m                 'Could not initialize camera.  Please see error trace.')\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not initialize camera.  Please see error trace."
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-sheffield",
   "metadata": {},
   "source": [
    "#### 創建顯示模組\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "label = widgets.Label(value=\"Waiting for data...\")\n",
    "display(image_widget,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-charge",
   "metadata": {},
   "source": [
    "#### 開啟yolov4-tiny-trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pycuda.autoinit\n",
    "from utils.yolo_classes import get_cls_dict\n",
    "from utils.display import open_window, set_display, show_fps\n",
    "from utils.visualization import BBoxVisualization\n",
    "from utils.yolo import TRT_YOLO\n",
    "trt_yolo = TRT_YOLO(\"yolov4-tiny-224\", (224, 224), 4)\n",
    "def getNearest(signs):\n",
    "    # Find the index of the sign with the largest width\n",
    "    largest_sign = max(signs, key=lambda x: x)\n",
    "    # Assuming that the signs array is paired with (width, class_id), return the sign data (e.g., class id and width)\n",
    "    return largest_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-thesis",
   "metadata": {},
   "source": [
    "#### 設定路牌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGN_INDEX_REVERSED = {\n",
    "    0: 'Maximum Speed Limit',\n",
    "    1: 'Minimum Speed Limit',\n",
    "    2: 'Pedestrian Crossing',\n",
    "    3: 'Railroad Crossing Warning',\n",
    "    4: 'Right Turn',\n",
    "    5: 'Stop',\n",
    "    6: 'Stop and Proceed'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-ceiling",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(change):\n",
    "    global angle, angle_last\n",
    "    image = change['new']\n",
    "    height = image.shape[0]\n",
    "    \n",
    "    # 裁剪影像\n",
    "    cropped_image = image[int(height * 0.4):, :, :]\n",
    "    \n",
    "    # 模型推理\n",
    "    xy = model_trt(preprocess(cropped_image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = xy[1]\n",
    "    widget_width,widget_height=224,224\n",
    "    x_pixel =int( x* widget_width / 2 + widget_width / 2)\n",
    "    y_pixel =int(y * widget_height / 2 + widget_height / 2)\n",
    "    \n",
    "    # 在圖片上繪製預測結果\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # 確保格式正確\n",
    "    cv2.circle(image, (x_pixel, y_pixel), 5, (0, 255, 0), -1)  # 綠色點表示預測位置\n",
    "    \n",
    "    \n",
    "    #### YOLO\n",
    "    boxes, confs, clss = trt_yolo.detect(image)\n",
    "    signs = []\n",
    "    for box, cls in zip(boxes, clss):\n",
    "        width = box[2] - box[0]\n",
    "        signs.append([width, cls])\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        label1 = SIGN_INDEX_REVERSED[int(cls)]\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box\n",
    "        cv2.putText(image, label1, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    # 更新 widget 顯示處理後的圖片\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "    # 更新標籤\n",
    "    label.value = f\"X: {x:.2f}, Y: {y:.2f}\\n\"+f\"signs:{signs}\"\n",
    "\n",
    "# 測試輸出\n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(1):\n",
    "    execute({'new': camera.value})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deluxe-london",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'camera' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0ed2353a763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'camera' is not defined"
     ]
    }
   ],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-pattern",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
