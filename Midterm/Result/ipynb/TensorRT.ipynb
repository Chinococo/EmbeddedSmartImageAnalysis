{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# 定義 PyTorch 模型\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.cuda().eval().half()  # 使用半精度運算\n",
    "\n",
    "# 加載已微調的權重\n",
    "model.load_state_dict(torch.load('../resnet18_finetuned_fp16_pruned.pth'))\n",
    "\n",
    "# 模擬輸入張量\n",
    "data = torch.zeros((1, 3, 224, 134)).cuda().half()\n",
    "\n",
    "# 將模型導出為 ONNX 格式\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    data,\n",
    "    \"resnet18_finetuned_fp16_pruned.onnx\",\n",
    "    export_params=True,            # 匯出模型權重\n",
    "    opset_version=11,               # ONNX 的運算子版本\n",
    "    do_constant_folding=True,       # 進行常量折疊優化\n",
    "    input_names=['input'],          # 輸入名稱\n",
    "    output_names=['output'],        # 輸出名稱\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}  # 動態批量大小\n",
    ")\n",
    "print(\"模型已成功轉換為 ONNX 格式\")\n"
   ],
   "id": "725863bac1d8bb46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:24:43.036303Z",
     "start_time": "2024-11-11T17:24:42.951629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorrt as trt\n",
    "import os\n",
    "\n",
    "# 設置 TensorRT Logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def build_engine_from_onnx(onnx_file_path, engine_file_path, fp16_mode=True):\n",
    "    # 建立 TensorRT Builder 和 Network\n",
    "    with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        \n",
    "        # 創建 Builder Config 並設置 max_workspace_size 和 fp16 模式\n",
    "        config = builder.create_builder_config()\n",
    "        config.max_workspace_size = 1 << 30  # 設置為 1GB，可以根據需求調整\n",
    "        if fp16_mode:\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "        \n",
    "        # 讀取 ONNX 文件並解析\n",
    "        if not os.path.exists(onnx_file_path):\n",
    "            print(f\"ONNX 文件 {onnx_file_path} 不存在\")\n",
    "            return None\n",
    "\n",
    "        with open(onnx_file_path, \"rb\") as model_file:\n",
    "            if not parser.parse(model_file.read()):\n",
    "                print(\"解析 ONNX 文件失敗\")\n",
    "                for error in range(parser.num_errors):\n",
    "                    print(parser.get_error(error))\n",
    "                return None\n",
    "\n",
    "        # 構建 TensorRT 引擎，並將配置對象傳遞給 build_engine\n",
    "        engine = builder.build_engine(network, config)\n",
    "        \n",
    "        # 將引擎保存到文件\n",
    "        if engine:\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                f.write(engine.serialize())\n",
    "            print(f\"TensorRT 引擎已成功保存到 {engine_file_path}\")\n",
    "        else:\n",
    "            print(\"引擎構建失敗\")\n",
    "\n",
    "        return engine\n",
    "\n",
    "# 指定 ONNX 文件路徑和生成的 TensorRT 引擎文件路徑\n",
    "onnx_file_path = \"resnet18_finetuned_fp16_pruned.onnx\"\n",
    "engine_file_path = \"resnet18_finetuned_fp16_pruned.trt\"\n",
    "\n",
    "# 調用函數進行轉換\n",
    "build_engine_from_onnx(onnx_file_path, engine_file_path, fp16_mode=True)\n"
   ],
   "id": "4ecddd388c3627b",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorrt_bindings.tensorrt.IBuilderConfig' object has no attribute 'max_workspace_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 47\u001B[0m\n\u001B[0;32m     44\u001B[0m engine_file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresnet18_finetuned_fp16_pruned.trt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# 調用函數進行轉換\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m \u001B[43mbuild_engine_from_onnx\u001B[49m\u001B[43m(\u001B[49m\u001B[43monnx_file_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine_file_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp16_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[19], line 13\u001B[0m, in \u001B[0;36mbuild_engine_from_onnx\u001B[1;34m(onnx_file_path, engine_file_path, fp16_mode)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trt\u001B[38;5;241m.\u001B[39mBuilder(TRT_LOGGER) \u001B[38;5;28;01mas\u001B[39;00m builder, builder\u001B[38;5;241m.\u001B[39mcreate_network(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m network, trt\u001B[38;5;241m.\u001B[39mOnnxParser(network, TRT_LOGGER) \u001B[38;5;28;01mas\u001B[39;00m parser:\n\u001B[0;32m     10\u001B[0m     \n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# 創建 Builder Config 並設置 max_workspace_size 和 fp16 模式\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     config \u001B[38;5;241m=\u001B[39m builder\u001B[38;5;241m.\u001B[39mcreate_builder_config()\n\u001B[1;32m---> 13\u001B[0m     \u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_workspace_size\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<<\u001B[39m \u001B[38;5;241m30\u001B[39m  \u001B[38;5;66;03m# 設置為 1GB，可以根據需求調整\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fp16_mode:\n\u001B[0;32m     15\u001B[0m         config\u001B[38;5;241m.\u001B[39mset_flag(trt\u001B[38;5;241m.\u001B[39mBuilderFlag\u001B[38;5;241m.\u001B[39mFP16)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tensorrt_bindings.tensorrt.IBuilderConfig' object has no attribute 'max_workspace_size'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "import os\n",
    "\n",
    "# 檢查模型檔案是否存在\n",
    "model_path = 'test_trt.pth'\n",
    "\n",
    "if not os.path.isfile(model_path):\n",
    "    print(f\"模型檔案未找到: {model_path}\")\n",
    "else:\n",
    "    print(\"模型檔案已找到，嘗試加載模型...\")\n",
    "\n",
    "    # 嘗試加載模型\n",
    "    try:\n",
    "        model_trt = TRTModule()\n",
    "        model_trt.load_state_dict(torch.load(model_path))\n",
    "        print(\"模型成功加載！\")\n",
    "        \n",
    "        # 嘗試創建執行上下文\n",
    "        if model_trt.engine:\n",
    "            context = model_trt.engine.create_execution_context()\n",
    "            if context:\n",
    "                print(\"成功創建執行上下文！模型可以使用。\")\n",
    "            else:\n",
    "                print(\"無法創建執行上下文。請檢查模型的正確性。\")\n",
    "        else:\n",
    "            print(\"模型引擎為 None，請檢查模型檔案或重新轉換。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"加載模型時出現錯誤:\", e)\n"
   ],
   "id": "30b3a135c61b5039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:05:13.544053Z",
     "start_time": "2024-11-11T17:05:13.436457Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dbdd0743c3e082b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸出差異: [[0.0007324 0.000977 ]]\n",
      "平均差異: 0.0008545\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T17:05:07.131967Z",
     "start_time": "2024-11-11T17:02:29.114780Z"
    }
   },
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "# 設定裝置 (若有 GPU 可用)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('test_trt.pth'))\n",
    "\n",
    "mean = torch.Tensor([0.4691, 0.4032, 0.4579]).cuda().half()\n",
    "std = torch.Tensor( [0.1740, 0.1485, 0.1688]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "\n",
    "# 設定資料夾路徑\n",
    "image_folder = \"../../Train/1600-v4\"\n",
    "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# 設定 widget 以顯示圖片\n",
    "widget_width = 224\n",
    "widget_height = 224\n",
    "image_widget = widgets.Image(format='jpeg', width=widget_width, height=widget_height)\n",
    "display(image_widget)\n",
    "\n",
    "# 設定裝置 (若有 GPU 可用)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def bgr8_to_jpeg(image):\n",
    "    _, jpeg = cv2.imencode('.jpg', image)\n",
    "    return jpeg.tobytes()\n",
    "\n",
    "def process_image(image_path):\n",
    "    # 讀取圖片並進行裁切\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # 裁切圖片的下部 60%\n",
    "    cropped_image = image[int(height * 0.4):, :, :]  # 保留從 40% 開始到高度底部的部分\n",
    "\n",
    "    # 調整裁切後的圖片大小為 224x134\n",
    "    cropped_image = cv2.resize(cropped_image, (224, 134))\n",
    "    \n",
    "    # 預處理圖片\n",
    "    input_tensor = preprocess(cropped_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    output = model_trt(input_tensor) \n",
    "    xy = model_trt(input_tensor).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    print(x,y/2)\n",
    "    # 映射預測的 (x, y) 到圖片的像素坐標，假設 x 和 y 是 [0, 1] 範圍內的預測\n",
    "    x_pixel = int(x * 224 / 2 + 224 / 2)\n",
    "    y_pixel = int(y * 134 / 2 + 134 / 2)\n",
    "    \n",
    "    # 在圖片上繪製預測結果\n",
    "    display_image = cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR)  # 確保格式正確\n",
    "    cv2.circle(display_image, (x_pixel, y_pixel), 5, (0, 255, 0), -1)  # 綠色點表示預測位置\n",
    "    \n",
    "    # 更新 widget 顯示處理後的圖片\n",
    "    image_widget.value = bgr8_to_jpeg(display_image)\n",
    "\n",
    "# 對資料夾中的每張圖片進行處理\n",
    "for image_file in image_files:\n",
    "    process_image(image_file)\n",
    "    time.sleep(2)  # 暫停以觀察每張圖片的結果\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chino\\AppData\\Local\\Temp\\ipykernel_53760\\3126848648.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_trt.load_state_dict(torch.load('test_trt.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "042e9f4a9dbe461bad57c6e57dd66ed4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0.30810547 -0.0919189453125\n",
      "0.32666016 -0.0767822265625\n",
      "0.20080566 -0.0611572265625\n",
      "0.30126953 -0.063232421875\n",
      "0.17333984 -0.058837890625\n",
      "0.359375 -0.064208984375\n",
      "0.2919922 -0.068359375\n",
      "0.19335938 -0.0631103515625\n",
      "0.28027344 -0.0631103515625\n",
      "0.21923828 -0.06298828125\n",
      "0.21228027 -0.0523681640625\n",
      "0.24804688 -0.0589599609375\n",
      "0.24707031 -0.0545654296875\n",
      "0.31152344 -0.078857421875\n",
      "0.23168945 -0.0621337890625\n",
      "0.38745117 -0.08642578125\n",
      "0.2529297 -0.0732421875\n",
      "0.3017578 -0.0546875\n",
      "0.32763672 -0.05810546875\n",
      "0.18652344 -0.0472412109375\n",
      "0.17236328 -0.061767578125\n",
      "0.31152344 -0.069091796875\n",
      "0.37939453 -0.072509765625\n",
      "0.11022949 -0.0667724609375\n",
      "0.14172363 -0.0640869140625\n",
      "0.38061523 -0.079833984375\n",
      "0.20666504 -0.0540771484375\n",
      "0.21655273 -0.0675048828125\n",
      "0.24902344 -0.0540771484375\n",
      "0.15795898 -0.0606689453125\n",
      "0.3022461 -0.0626220703125\n",
      "0.30249023 -0.0552978515625\n",
      "0.32348633 -0.05859375\n",
      "0.21069336 -0.0697021484375\n",
      "0.2277832 -0.0479736328125\n",
      "0.28173828 -0.0914306640625\n",
      "0.28271484 -0.0572509765625\n",
      "0.2644043 -0.0799560546875\n",
      "0.24511719 -0.0633544921875\n",
      "0.24633789 -0.0634765625\n",
      "0.19006348 -0.0662841796875\n",
      "0.33496094 -0.07666015625\n",
      "0.23779297 -0.0587158203125\n",
      "0.28100586 -0.0482177734375\n",
      "0.2421875 -0.0604248046875\n",
      "0.33203125 -0.0537109375\n",
      "0.29223633 -0.0704345703125\n",
      "0.14685059 -0.0433349609375\n",
      "0.17932129 -0.070068359375\n",
      "0.24438477 -0.0504150390625\n",
      "0.30273438 -0.08935546875\n",
      "0.23071289 -0.0718994140625\n",
      "0.3095703 -0.0723876953125\n",
      "0.24487305 -0.0699462890625\n",
      "0.28466797 -0.07861328125\n",
      "0.09851074 -0.0645751953125\n",
      "0.3383789 -0.0576171875\n",
      "0.34423828 -0.086181640625\n",
      "0.28076172 -0.047119140625\n",
      "0.28051758 -0.0731201171875\n",
      "0.33935547 -0.077392578125\n",
      "0.32739258 -0.0526123046875\n",
      "0.23730469 -0.06591796875\n",
      "0.27685547 -0.0552978515625\n",
      "0.20690918 -0.0677490234375\n",
      "0.35229492 -0.057373046875\n",
      "0.25146484 -0.0609130859375\n",
      "0.24731445 -0.0638427734375\n",
      "0.26220703 -0.06884765625\n",
      "0.1809082 -0.054931640625\n",
      "0.34350586 -0.0732421875\n",
      "0.3232422 -0.0716552734375\n",
      "0.20495605 -0.063720703125\n",
      "0.42260742 -0.0809326171875\n",
      "0.12243652 -0.04931640625\n",
      "0.2902832 -0.08349609375\n",
      "0.20947266 -0.0677490234375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 92\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image_file \u001B[38;5;129;01min\u001B[39;00m image_files:\n\u001B[0;32m     91\u001B[0m     process_image(image_file)\n\u001B[1;32m---> 92\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 暫停以觀察每張圖片的結果\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af34aa4830dab16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
