{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "# IPython Libraries for display and widgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Camera and Motor Interface for JetBot\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Basic Python packages for image annotation\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import csv\n",
    "import ipywidgets as widgets\n",
    "from jetbot import Robot\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "import torch\n",
    "import cv2\n",
    "import traitlets\n",
    "import numpy as np\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from torchvision import models, transforms\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import traitlets\n",
    "import numpy as np\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from torchvision import models, transforms\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exceptional-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570b007c0a6641289607d81f7100c8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='224', width='224'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<traitlets.traitlets.directional_link at 0x7f30300400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化相機\n",
    "camera = Camera.instance(width=224, height=224,fps=5)\n",
    "\n",
    "# 設定 widget 大小\n",
    "widget_width = 224\n",
    "widget_height = 224\n",
    "\n",
    "# 建立顯示影像的 widget 和 x, y 控制滑桿\n",
    "image_widget = widgets.Image(format='jpeg', width=widget_width, height=widget_height)\n",
    "#target_widget = widgets.Image(format='jpeg', width=widget_width, height=widget_height)\n",
    "#x_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='x')\n",
    "#y_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='y')\n",
    "\n",
    "# 顯示 widget\n",
    "display(widgets.HBox([image_widget]))\n",
    "\n",
    "# 啟動相機影像的即時處理和推論\n",
    "time.sleep(1)  # 確保相機啟動完成\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "#traitlets.dlink((camera, 'value'), (target_widget, 'value'), transform=process_and_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "careful-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "original-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Execution time: 18.7670 seconds\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 設定裝置 (若有 GPU 可用)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 加載模型\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(torch.load(\"resnet18_50_1e-05_.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()  # 將模型設定為推論模式\n",
    "\n",
    "# 裁剪影像的函數 (直接回傳裁剪後的影像)\n",
    "def crop_top_40_percent(image):\n",
    "    width, height = image.size\n",
    "    new_height = int(height * 0.6)\n",
    "    cropped_img = image.crop((0, height - new_height, width, height))\n",
    "    return cropped_img\n",
    "\n",
    "# 修改 execute 函數來使用裁剪後的影像\n",
    "def execute(change):\n",
    "    start_time = time.time()  # 開始計時\n",
    "    \n",
    "    # 將輸入影像轉換為 PIL Image（如果需要）\n",
    "    image = change['new']\n",
    "    if isinstance(image, np.ndarray):  # 檢查是否為 numpy 陣列\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "    # 裁剪影像\n",
    "    cropped_image = crop_top_40_percent(image)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4691, 0.4032, 0.4579], [0.1740, 0.1485, 0.1688])\n",
    "    ])\n",
    "    input_tensor = transform(cropped_image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        x, y = output[0].cpu().numpy()\n",
    "    print(x,y)\n",
    "    end_time = time.time()  # 結束計時\n",
    "    execution_time = end_time - start_time  # 計算間隔時間\n",
    "    print(f'Execution time: {execution_time:.4f} seconds')\n",
    "\n",
    "# 呼叫 execute 函數，這裡的 change['new'] 應包含 PIL Image 物件或 numpy 陣列\n",
    "execute({'new': camera.value})  # 假設 camera.value 是 numpy 陣列\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supposed-dictionary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.1587 seconds\n"
     ]
    }
   ],
   "source": [
    "camera.unobserve(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-nightlife",
   "metadata": {},
   "source": [
    "# 測試秒數TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "external-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.1861 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('resnet34_final_trt.pth'))\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device('cuda')\n",
    "mean = torch.Tensor([0.4691, 0.4032, 0.4579]).cuda().half()\n",
    "std = torch.Tensor([0.1740, 0.1485, 0.1688]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def execute(change):\n",
    "    start_time = time.time()  # 開始計時\n",
    "    global angle, angle_last,integral\n",
    "    image = change['new']\n",
    "    xy = model_trt(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    end_time = time.time()  # 結束計時\n",
    "    execution_time = end_time - start_time  # 計算間隔時間\n",
    "    print(f'Execution time: {execution_time:.4f} seconds')\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
